{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b7f9a1e4-d66a-4a9e-a046-19d51e4a0e67",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Scoring the Accident Images \n",
    "\n",
    "In this notebook, we'll show how to score the incoming images of damaged vehicles as they flow into the system to come up with a damage severity score using the model that we previously training and promoted to the production.\n",
    "\n",
    "The end results are stored in the `accident_images` delta table\n",
    "\n",
    "*Note: we could also have these transformations available in a Delta Live Table. Open [02.2-EXTRA-Batch-Scoring-DLT]($./EXTRA-DLT-inference/02.2-EXTRA-Batch-Scoring-DLT) to see how it's done.*\n",
    "\n",
    "\n",
    "<!-- Collect usage data (view). Remove it to disable collection or disable tracker during installation. View README for more details.  -->\n",
    "<img width=\"1px\" src=\"https://ppxrzfxige.execute-api.us-west-2.amazonaws.com/v1/analytics?category=lakehouse&org_id=984752964297111&notebook=%2F02-Data-Science-ML%2F02.2-Batch-Scoring&demo_name=lakehouse-fsi-smart-claims&event=VIEW&path=%2F_dbdemos%2Flakehouse%2Flakehouse-fsi-smart-claims%2F02-Data-Science-ML%2F02.2-Batch-Scoring&version=1&user_hash=3d9550665f4179aba1791a587dee6d56e218186d3a057ad2d2c3ad58a351ed5c\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d5b3fa47-b9ac-42d4-b16e-c288fff8c2cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": null
    }
   },
   "source": [
    "### A cluster has been created for this demo\n",
    "To run this demo, just select the cluster `dbdemos-lakehouse-fsi-smart-claims-thomas_hass` from the dropdown menu ([open cluster configuration](https://adb-984752964297111.11.azuredatabricks.net/#setting/clusters/0802-065525-9zzx4cdb/configuration)). <br />\n",
    "*Note: If the cluster was deleted after 30 days, you can re-create it with `dbdemos.create_cluster('lakehouse-fsi-smart-claims')` or re-install the demo: `dbdemos.install('lakehouse-fsi-smart-claims')`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c4bf660d-1a0f-4658-9a77-d09a7bab6d4f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install mlflow==2.20.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "50bb3d4b-b80c-4881-b198-9242a0a091e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%run ../_resources/00-setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "42600225-6d8b-4393-9b8a-98560d9a8fcb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.store.artifact.models_artifact_repo import ModelsArtifactRepository\n",
    "import mlflow\n",
    "# Use the Unity Catalog model registry\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "# download model requirement from remote registry\n",
    "requirements_path = ModelsArtifactRepository(f\"models:/{catalog}.{db}.dbdemos_claims_damage_level@prod\").download_artifacts(artifact_path=\"requirements.txt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eb1d3346-c0f4-4dcc-b91c-1f38c854b38b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -r $requirements_path\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aa7c9f37-f442-47bb-b7aa-bbed0588ef06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%run ../_resources/00-setup $reset_all_data=false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a65c580a-de9e-4d6c-9160-584d341c1c8f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Incrementally ingest the raw incoming images\n",
    "\n",
    "New images can typically land in a cloud storage (S3/ADLS/GCS), mounted within Unity Catalog using Volumes. \n",
    "\n",
    "Let's start by ingesting them and saving them as a Delta Lake table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "57924e6a-0cb4-4a5e-bcd5-cdc5d61c1181",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Incrementally load the raw incoming JPG images"
    }
   },
   "outputs": [],
   "source": [
    "volume_path = f\"/Volumes/{catalog}/{db}/{volume_name}\"\n",
    "\n",
    "(spark.readStream\n",
    "            .format(\"cloudFiles\")\n",
    "            .option(\"cloudFiles.format\", \"binaryFile\")\n",
    "            .option(\"cloudFiles.schemaLocation\", f\"{volume_path}/checkpoint/images_shema\")\n",
    "            .load(f\"{volume_path}/Accidents/images\")\n",
    "            .withColumn(\"image_name\", F.regexp_extract(F.col(\"path\"), r\".*/(.*?.jpg)\", 1))\n",
    "      .writeStream\n",
    "            .option(\"checkpointLocation\", f\"{volume_path}/checkpoint/images\")\n",
    "            .trigger(availableNow=True)\n",
    "            .table(\"raw_accident_image\")).awaitTermination()\n",
    "\n",
    "display(spark.table(\"raw_accident_image\").limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "704b3c5a-8676-466f-b986-913f646a75fd",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Incrementally load the image metadata"
    }
   },
   "outputs": [],
   "source": [
    "(spark.readStream\n",
    "            .format(\"cloudFiles\")\n",
    "            .option(\"cloudFiles.format\", \"csv\")\n",
    "            .option(\"cloudFiles.inferColumnTypes\", \"true\")\n",
    "            .option(\"cloudFiles.schemaLocation\", f\"{volume_path}/checkpoint/images_m_shema\")\n",
    "            .load(f\"{volume_path}/Accidents/metadata\")\n",
    "      .writeStream\n",
    "            .option(\"checkpointLocation\", f\"{volume_path}/checkpoint/images_m\")\n",
    "            .trigger(availableNow=True)\n",
    "            .table(\"raw_accident_metadata\")).awaitTermination()\n",
    "            \n",
    "display(spark.table(\"raw_accident_metadata\").limit(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "87328e5d-9a42-45b2-b105-57a9cc382d9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Score the damaged vehicle image to determine damage severity\n",
    "\n",
    "Our claim images are now added to our tables and easily accessible. Let's load our model from Unity Catalog to score the damage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "273eb428-44ac-4116-91fb-4bfa6d77c3b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "model_name = \"dbdemos_claims_damage_level\"\n",
    "\n",
    "mlflow.set_registry_uri('databricks-uc')\n",
    "\n",
    "#Loading the model from UC\n",
    "predict_damage_udf = mlflow.pyfunc.spark_udf(spark, model_uri=f\"models:/{catalog}.{db}.{model_name}@prod\")\n",
    "spark.udf.register(\"predict_damage\", predict_damage_udf)\n",
    "columns = predict_damage_udf.metadata.get_input_schema().input_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bbabfa3e-6f25-4638-a471-8674fed3da44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Test inferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8b671a77-316a-4147-ae95-81db7f6e0f73",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql \n",
    "SELECT image_name, predict_damage(content) as damage_prediction, content FROM raw_accident_image LIMIT 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "82274022-d2c6-4a7b-8657-1fef3d17152d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "raw_images = (spark.read.table(\"raw_accident_image\")\n",
    "                   .withColumn(\"damage_prediction\", predict_damage_udf(*columns)))\n",
    "\n",
    "#Only process 1k claims for the demo to run faster\n",
    "metadata = spark.table(\"raw_accident_metadata\").orderBy(F.rand()).limit(1000)\n",
    "\n",
    "raw_images.join(metadata, on=\"image_name\").write.mode('overwrite').saveAsTable(\"accident_images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5ca4f694-3b79-4076-842d-47b3329aa380",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.table(\"accident_images\").limit(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6e5444f4-c076-4d19-b662-69cfeb02c1a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Real time inference\n",
    "\n",
    "While this use-case is working with batch inferences (consuming incremental new data in a stream), we could also deploy our model behind a [Serverless model endpoint](#mlflow/endpoints). \n",
    "\n",
    "Images can be sent as base64 data over the endpoint. For more details on how to do that, you can run `dbdemos.install('computer-vision-pcb')`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "674f442d-9f61-4d4d-b0b0-77095b9c4e6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Add telematics and accident data to the claims & policy data\n",
    "\n",
    "Telematics data is joined with Claims and Policy data to monitor the behavior of the driver before the accident. End results are stored into \"claim_policy_accident\" delta table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "48391075-7f3c-4878-a530-3b890e0c0c8d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE TABLE claim_policy_accident AS \n",
    "  SELECT\n",
    "    t.*,\n",
    "    a.* EXCEPT (chassis_no, claim_no)\n",
    "  FROM\n",
    "    claim_policy_telematics t\n",
    "    JOIN accident_images a USING(claim_no)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c1e1db6f-2020-47cf-b86b-2a7ea693125d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Conclusion\n",
    "\n",
    "In this notebook, we demonstrated how to <b> retrieve the model </b> from Unity Catalog and run inferences to <b> score </b> on new image data and persist the results back into delta tables. \n",
    "\n",
    "Telematics data, accident image data, claims & policy data </b> are all joined together to provide a 360 view of the accident scene to the claims investigation officer to <b>reconstruct the scene</b> and make a decision on what to do next. Eg. release funds, authorize the car for repairs, approve rental loaner car or send for further investigation.\n",
    "\n",
    "Open notebook [02.3-Dynamic-Rule-Engine]($./02.3-Dynamic-Rule-Engine) to see how dynamic rules can be implemented to start processing our claims faster based on this information."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "02.2-Batch-Scoring",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
